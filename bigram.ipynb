{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aa06dbe-e5a2-49df-a135-47a6c74ced23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#handles lot of math,calculus, linear algebra with \n",
    "#type of data structure called tensors\n",
    "\n",
    "#32:18\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "#PyTorch checks if CUDA (i.e., NVIDIA GPU support) is available.\n",
    "block_size=8\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc32522-a78e-401a-9382-9aa5713302e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232081\n",
      "DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "  BY\n",
      "\n",
      "  L. FRANK BAU\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text=f.read()\n",
    "print(len(text))\n",
    "print(text[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7edf6369-58d7-403b-98cd-ed9ed9b8c988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(set(text))\n",
    "print(chars)\n",
    "vocab_size=len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24188b99-fc4a-43a6-9b06-53c4e45651c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does job of tokenizer\n",
    "\n",
    "string_to_int={ ch:i for i,ch in enumerate(chars) }\n",
    "#maps each character to unique integer\n",
    "#enumerate: built it py func which gives the index to list\n",
    "#\"Go through each character in chars,\n",
    "#and make a dictionary where the character (ch) maps to its index (i).\"\n",
    "\n",
    "\n",
    "int_to_string={ i:ch for i,ch in enumerate(chars) }\n",
    "#int_to_string[0]  # gives 'a'\n",
    "#int_to_string[1]  # gives 'b'\n",
    "#int_to_string[2]  # gives 'c'\n",
    "\n",
    "encode= lambda s: [string_to_int[c] for c in s]\n",
    "#encode(\"abc\")  # ➝ [0, 1, 2]\n",
    "# takes a string s, goes thriugh each cahracter c in s and gives the number\n",
    "\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "#decode([0, 1, 2])  # ➝ \"abc\"\n",
    "#takes a list of ints l, goes through each element i in l,looks up \n",
    "#the char for that number , joins all chars together in 1 string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bc45d79-81b7-4528-864d-6cf9693e513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60, 57, 64, 64, 67]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "a=encode('hello')\n",
    "b=decode(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec209f3a-55b2-4999-b24c-3a7b68752892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([27, 38, 41, 38, 43, 31, 48,  1, 24, 37, 27,  1, 43, 31, 28,  1, 46, 32,\n",
      "        49, 24, 41, 27,  1, 32, 37,  1, 38, 49,  0,  0,  1,  1, 25, 48,  0,  0,\n",
      "         1,  1, 35, 10,  1, 29, 41, 24, 37, 34,  1, 25, 24, 44, 36,  0,  0,  1,\n",
      "         1, 24, 44, 43, 31, 38, 41,  1, 38, 29,  1, 43, 31, 28,  1, 46, 32, 49,\n",
      "        24, 41, 27,  1, 38, 29,  1, 38, 49,  8,  1, 43, 31, 28,  1, 35, 24, 37,\n",
      "        27,  1, 38, 29,  1, 38, 49,  8,  1, 38])\n"
     ]
    }
   ],
   "source": [
    "data =torch.tensor(encode(text),dtype=torch.long)\n",
    "#core step in preparing data for a PyTorch model\n",
    "#encodes, then datatype---torch.long(64 bit seq--IMP)-->coz, If you're feeding token indices (like 0, 1, 2, etc.) \n",
    "#into a model, especially into an embedding layer, it must be of type torch.long\n",
    "#torch.tensor()--->converts to someking of numpy array \n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "432c2d72-465a-4cd3-aecc-bebd421467f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n= int(0.8*len(data))\n",
    "train_data=data[:n]\n",
    "val_data= data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad08f7b-12e8-4229-be6d-85d08b600058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([27]) target is tensor(38)\n",
      "when input is tensor([27, 38]) target is tensor(41)\n",
      "when input is tensor([27, 38, 41]) target is tensor(38)\n",
      "when input is tensor([27, 38, 41, 38]) target is tensor(43)\n",
      "when input is tensor([27, 38, 41, 38, 43]) target is tensor(31)\n",
      "when input is tensor([27, 38, 41, 38, 43, 31]) target is tensor(48)\n",
      "when input is tensor([27, 38, 41, 38, 43, 31, 48]) target is tensor(1)\n",
      "when input is tensor([27, 38, 41, 38, 43, 31, 48,  1]) target is tensor(24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    print('when input is',context,'target is',target)\n",
    "\n",
    "#This simulates how a model is trained:\n",
    "#It sees a partial sequence (like typing in autocomplete).\n",
    "#It has to predict the next token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e8643-814a-4f01-8bbc-2d9f7ee383b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
